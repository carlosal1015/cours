\documentclass{yann}
\usepackage{dsfont}

\renewcommand{\T}{\mathscr{T}}
\newcommand{\Part}{\mathcal{P}}
\newcommand{\Pro}{\bigl(Œ©,\T\bigr)}
\newcommand{\Prob}{\bigl(Œ©,\T,‚Ñô\bigr)}
\newcommand{\SEnsemble}[2]{\{ #1 \;|\; #2 \}}
\newcommand{\LProb}{\LL1\Prob}
\newcommand{\LL}[1]{\mathcal{L}^{#1}}
\newcommand{\Cov}{\mathop{\mathrm{Cov}}}
\newcommand{\me}{e}
\newcommand{\I}{i}

\begin{document}
\title{Variables al√©atoires discr√®tes}
\maketitle

\Para{Notations}

Dans tout le chapitre
\begin{itemize}
\item
  $\Pro$ d√©signe un espace probabilisable;
\item
  $\Prob$ d√©signe un espace probabilis√©;
\item
  Toutes les variables al√©atoires consid√©r√©es seront des variables al√©atoires \emph{discr√®tes}.
\end{itemize}

% -----------------------------------------------------------------------------
\section{G√©n√©ralit√©s}

\subsection{Variables al√©atoires discr√®tes}

\Para{D√©finition}

Une \emph{variable al√©atoire discr√®te} $X$ sur $\Pro$ est une fonction $\Fn{X}{Œ©}{E}$ telle que
\begin{itemize}
\item
  l'image $X(Œ©)$ de $X$ est au plus d√©nombrable;
\item
  pour tout $x‚ààX(Œ©)$, l'ensemble $X^{-1}\bigl(\{ x \}\bigr)$ est un √©l√©ment de la tribu $\T$.
\end{itemize}

\Para{Lemme}

Dans ces conditions, pour toute partie $A$ de $E$, on a $X^{-1}(A)‚àà\T$.
On note \og{}$X‚ààA$\fg{} l'√©v√©nement $X^{-1}(A)$.

\Para{D√©finition.}

Soit $X$ une variable al√©atoire sur $\Pro$.
On dit que \emph{$X$ est √† valeurs dans $F$} ¬£ssi. $X(Œ©)‚äÇF$.

\subsection{Loi d'une variable al√©atoire discr√®te}

\Para{D√©finition}

Soit $X$ une variable al√©atoire sur $\Prob$ √† valeurs dans $E$.
La \emph{loi} de $X$ est l'application
\[ \Fonction{‚Ñô_X}{\Part(E)}{[0,1]}{A}{ ‚Ñô(X‚ààA) = ‚Ñô\bigl(X^{-1}(A)\bigr) } \]
Il s'agit d'une probabilit√© sur l'espace probabilisable $\bigl(E,\Part(E)\bigr)$.

\Para{Proposition}

Soit $X$ une variable al√©atoire sur $\Prob$ √† valeurs dans $E$.
On suppose $E = \SEnsemble{x_n}{n‚àà‚Ñï}$ o√π les $x_n$ sont deux √† deux distincts.
Alors la suite $p_n = ‚Ñô(X = x_n)$ caract√©rise la loi de la suite $‚Ñô_X$.
Plus pr√©cis√©ment, pour tout $A‚äÇE$ on a
\[ ‚Ñô_X(A) = ‚àë_{\substack{n‚àà‚Ñï\\ x_n‚ààA}} p_n \]

\Para{Th√©or√®me d'existence}

Soit $X$ une variable al√©atoire sur $\Pro$ telle que
$X(Œ©) = \SEnsemble{x_n}{n‚àà‚Ñï}$ o√π les $x_n$ sont deux √† deux distincts.
Soit $(p_n)_{n‚àà‚Ñï}$ une suite de r√©els positifs telle que la s√©rie $‚àë_n p_n$ converge et $‚àë_{n‚â•0} p_n = 1$.
Alors il existe une probabilit√© $‚Ñô$ sur $\Pro$ telle que
\[ ‚àÄn‚àà‚Ñï\+‚Ñô(X=x_n) = p_n. \]

\Para{Remarque}

Il n'y a pas unicit√© en g√©n√©ral.

\subsection{Fonction de r√©partition d'une variable al√©atoire r√©elle}

\Para{D√©finition}

Soit $X$ une variable al√©atoire r√©elle sur $\Prob$.
La \emph{fonction de r√©partition de $X$} est la fonction $\Fn{F_X}{‚Ñù}{‚Ñù}$ d√©finie par
\[ F_X(x) = ‚Ñô(X‚â§x) = ‚Ñô_X(\intOF{-‚àû,x}). \]

\Para{Propri√©t√©s}

Soit $X$ une variable al√©atoire r√©elle sur $\Prob$
et $F_X$ sa fonction de r√©partition.
Alors, pour $(a,b) ‚àà‚Ñù^2$, on a
\begin{enumerate}
\item
  $F_X$ est croissante sur $‚Ñù$;
\item
  $\DS \lim_{-‚àû} F_X = 0$;
\item
  $\DS \lim_{+‚àû} F_X = 1$;
\item
  Si $a < b$, alors $\DS ‚Ñô( a < X ‚â§b ) = F_X(b) - F_X(a)$;
\item
  $F_X$ est \emph{continue √† droite}, c.-√†-d.
  $\DS\lim_{x\to a^+} F_X(x) = F_X(a)$;
\item
  $\DS \lim_{x \to a^-} F_X(x) = ‚Ñô(X < a)$;
\item
  $\DS ‚Ñô(X = a) = F_X(a) - \lim_{x \to a^-} F_X(x)$.
\end{enumerate}

\Para{Th√©or√®me}

Soit $X$ et $Y$ deux variables al√©atoires r√©elles sur $\Prob$.
Alors $X$ et $Y$ ont la m√™me fonction de r√©partition ¬£ssi. $X$ et $Y$ ont m√™me loi.
\[ F_X = F_Y \iff ‚Ñô_X = ‚Ñô_Y. \]

\subsection{Fonction d'une ou de plusieurs variables al√©atoires}

\Para{Lemme}

Soit $\Prob$ un espace probabilis√©, $\Fn{X}{Œ©}{E}$ et $\Fn{Y}{Œ©}{F}$ deux variables al√©atoires.
On pose $Z = (X,Y)$, c.-√†-d.
\[ \Fonction{Z}{Œ©}{E√óF}{œâ}{\bigl( X(œâ), Y(œâ) \bigr)} \]
Alors $Z$ est une variable al√©atoire discr√®te √† valeurs dans $E√óF$.

Cela se g√©n√©ralise imm√©diatement au cas de $n$ variables al√©atoires.

\Para{Proposition-D√©finition}

Soit $X$ une variable al√©atoire sur $\Pro$ √† valeurs dans $E$
et $\Fn{f}{E}{F}$ une application quelconque.
On note $f(X)$ la fonction $f‚ó¶X$; il s'agit d'une variable al√©atoire discr√®te.

\Para{Corollaire}

Soit $\Prob$ un espace probabilis√©.
On consid√®re $n$ variables al√©atoires discr√®tes $\Fn{X_i}{Œ©}{E_i}$ pour $i‚àà\Dcro{1,n}$.
Soit $\Fn{f}{‚àè_{i=1}^n E_i}{F}$ une application quelconque.
Alors $Y = f(X_1,X_2,\dots,X_n)$ est une variable al√©atoire discr√®te.

% -----------------------------------------------------------------------------
\section{Esp√©rance}

\subsection{Variables al√©atoires discr√®tes d'esp√©rances finies}

\Para{D√©finition}

Soit $X$ une variable al√©atoire r√©elle sur $\Prob$.
On suppose que $X(Œ©)‚äÇ\SEnsemble{x_n}{n‚àà‚Ñï}‚äÇ‚Ñù$ o√π les $x_n$ sont deux √† deux distincts.
On dit que $X$ est \emph{d'esp√©rance finie} ¬£ssi. la s√©rie $‚àë_n x_n \, ‚Ñô(X = x_n)$ converge absolument.
Quand c'est le cas, appelle esp√©rance de $X$ le r√©el
\[ ùîº(X) = ‚àë_{n=0}^{+‚àû} x_n \, ‚Ñô(X=x_n) \]

On admet que cette d√©finition ne d√©pend pas du choix de la suite $(x_n)_{n‚àà‚Ñï}$.

\Para{Formule de transfert}

Soit $E = \SEnsemble{x_n}{n‚àà‚Ñï}$ o√π les $x_n$ sont deux √† deux distincts.
Soit $X$ une variable al√©atoire √† valeurs dans $E$
et $\Fn{f}{E}{‚Ñù}$ une application quelconque.
Alors la variable al√©atoire $f(X)$ est d'esp√©rance finie
¬£ssi. la s√©rie $‚àë_n f(x_n) \, ‚Ñô(X = x_n)$ converge absolument.
Dans ce cas, on a
\[ ùîº\bigl( f(X) \bigr) = ‚àë_{n=0}^{+‚àû} f(x_n) \, ‚Ñô(X=x_n). \]

\Para{Proposition}[variables al√©atoires √©gales p.s.]

Soit $X$ et $Y$ deux variables al√©atoires discr√®tes √† valeurs dans $E$.
On suppose que $X = Y$ presque s√ªrement, ¬£cad. que $‚Ñô(X=Y) = 1$.
\begin{enumerate}
\item
  Dans le cas $E = ‚Ñù$,
  $X$ est d'esp√©rance finie ¬£ssi. $Y$ l'est.
  Dans ce cas, on a $ùîº(X) = ùîº(Y)$.
\item
  Plus g√©n√©ralement, si $f$ est une fonction $E \to ‚Ñù$,
  $f(X)$ est d'esp√©rance finie ¬£ssi. $f(Y)$ l'est.
  Dans ce cas, on a $ùîº(f(X)) = ùîº(f(Y))$.
\end{enumerate}

\Para{Proposition}

Soit $X$ et $Y$ deux variables al√©atoires r√©elles sur $\Prob$.
\begin{enumerate}
\item
  $X$ est d'esp√©rance finie ¬£ssi. $\Abs{X}$ est √©galement d'esp√©rance finie.
\item
  Si $\Abs{X}‚â§Y$ presque s√ªrement, c.-√†-d. si $‚Ñô\bigl(\Abs{X}‚â§Y\bigr) = 1$,
  et si $Y$ est d'esp√©rance finie, alors $X$ est √©galement d'esp√©rance finie.
\item
  En particulier, si $X$ est born√©e, alors $X$ est d'esp√©rance finie.
\item
  Si $X$ et $Y$ sont d'esp√©rances finies, et $(Œª,Œº)‚àà‚Ñù^2$,
  alors $ŒªX+ŒºY$ est √©galement d'esp√©rance finie.
\end{enumerate}

\Para{Proposition}

Soit $X$ et $Y$ deux variables al√©atoires r√©elles
d'esp√©rances finies sur $\Prob$.
On a
\begin{enumerate}
\item
  Si $Œª$ et $Œº$ sont des r√©els, alors $ùîº(ŒªX +ŒºY) = Œªùîº(X) + Œºùîº(Y)$.
\item
  Si $X‚â•0$ presque s√ªrement, alors $ùîº(X)‚â•0$.
\item
  Si $X‚â§Y$ presque s√ªrement, alors $ùîº(X)‚â§ùîº(Y)$.
\item
  Si $X = a$ presque s√ªrement, alors $ùîº(X) = a$.
\item
  Si $ùîº\bigl( \Abs{X} \bigr) = 0$, alors $X = 0$ presque s√ªrement.
\item
  Si $A‚äÇ‚Ñù$, alors $‚Ñô(X‚ààA) = ùîº\bigl( \mathds{1}_A(X) \bigr)$.
\item
  $\bigl| ùîº(X) \bigr| ‚â§ùîº\bigl( |X| \bigr)$.
\end{enumerate}

\Para{D√©finition}

Une variable al√©atoire r√©elle $X$ d'esp√©rance finie est dite \emph{centr√©e} ¬£ssi. $ùîº(X) = 0$.

\Para{Proposition}[in√©galit√© de Markov]

Soit $\Prob$ un espace probabilis√© et $X$ une variable al√©atoire discr√®te d'esp√©rance finie.
Si $X$ est √† valeurs dans $‚Ñù^+$ (presque s√ªrement) et si $a > 0$, alors
\[ ‚Ñô(X‚â•a) ‚â§ \frac{ùîº(X)}{a}. \]

\subsection{Moments d'une variable al√©atoire r√©elle}

\Para{D√©finition}

Soit $X$ une variable al√©atoire r√©elle sur $\Prob$.
Soit $p‚àà‚Ñï$.
On dit que \emph{$X$ admet un moment d'ordre $p$} ¬£ssi. la variable al√©atoire $X^p$ est d'esp√©rance finie,
et on appelle \emph{moment d'ordre $p$ de $X$} le r√©el $ùîº(X^p)$.

On note $\LL p\Prob$ l'ensemble des variables al√©atoires r√©elles sur $\Prob$ qui admettent un moment d'ordre $p$.
On notera $\LL p$ au lieu de $\LL p\Prob$ lorsque le contexte le permettra.

\Para{Proposition}

Pour tout $p‚àà‚Ñï$, $\LL p$ est un espace vectoriel.
De plus,
\begin{itemize}
\item
  $\LL0$ est l'ensemble des variables al√©atoires r√©elles discr√®tes sur $\Pro$;
\item
  $\LL1$ est l'ensemble des variables al√©atoires r√©elles discr√®tes sur $\Prob$ d'esp√©rance finie.
\end{itemize}

\Para{Proposition}

Soit $(p,q)‚àà‚Ñï^2$ tels que $p‚â§q$.
Alors $\LL q ‚äÇ\LL p$.

\Para{Corollaire}

Soit $X$ une variable al√©atoire r√©elle. Si $X$ admet un moment d'ordre 2,
alors $X$ est d'esp√©rance finie.

\Para{Proposition}

Si $X$ et $Y$ sont deux variables al√©atoires de $\LL2$,
alors $XY‚àà\LL1$.
De plus, on a l'in√©galit√© de Cauchy-Schwarz,
\[ ùîº(XY)^2 ‚â§ùîº(X^2) \,ùîº(Y^2). \]

\Para{D√©finition}

Soit $X$ une variable al√©atoire r√©elle d'esp√©rance finie.
Notons $Y = \bigl(X -ùîº(X)\bigr)^2$.
Si $Y$ est d'esp√©rance finie,
on dit que $X$ est \emph{de variance finie},
et on appelle \emph{variance de $X$} le r√©el $ùîº(Y)$.

\Para{Proposition}

Une variable al√©atoire r√©elle est de variance finie ¬£ssi. elle est dans $\LL2$.

\Para{Proposition}

Soit $X‚àà\LL2$.
\begin{enumerate}
\item
  \emph{Formule de K√∂nig-Huygens}: $ùïç(X) = ùîº(X^2) -ùîº(X)^2$.
\item
  Si $a‚àà‚Ñù$, alors $ùïç(aX) = a^2 ùïç(X)$ et $ùïç(X+a) = ùïç(X)$.
\item
  On a $ùïç(X) = 0$ ¬£ssil. existe $a‚àà‚Ñù$ tel que $X = a$ presque s√ªrement.
  Dans ce cas, $a = ùîº(X)$.
\end{enumerate}

\Para{In√©galit√© de Bienaym√©-Tchebychev}

Soit $X$ une variable al√©atoire r√©elle de variance finie $œÉ^2$ et d'esp√©rance $Œº$.
Pour tout $Œ±>0$, on a
\[ ‚Ñô \bigPa{ \Abs{X-Œº} ‚â• Œ± } ‚â§ \frac{œÉ^2}{Œ±^2} \]

\subsection{Fonctions g√©n√©ratrices}

On s'int√©resse ici au cas des variables al√©atoires discr√®tes √† valeurs dans $‚Ñï$.

\Para{D√©finition}

Soit $X$ une variable al√©atoire r√©elle √† valeurs dans $‚Ñï$.
On appelle \emph{fonction g√©n√©ratrice de $X$} la fonction $G_X$ d√©finie par
$G_X(t) = ùîº\bigl(t^X\bigr)$.

\Para{Proposition}

Avec les m√™mes notations, posons $p_n = ‚Ñô(X=n)$. On a
\[ G_X(t) = ‚àë_{n=0}^{+‚àû} p_n t^n. \]
$G_X$ est la somme d'une s√©rie enti√®re.
De plus,
\begin{itemize}
\item
  son rayon de convergence $R_X$ v√©rifie $R_X‚â•1$;
\item
  elle converge absolument sur $\intF{-1,1}$ (au moins);
\item
  elle est continue sur $\intF{-1,1}$;
\item
  elle est de classe $\CC‚àû$ sur $\intO{-R_X,R_X}$, et en particulier sur $\intO{-1,1}$.
\end{itemize}

\Para{Proposition}

Soit $X$ et $Y$ deux variables al√©atoires sur $\Prob$ √† valeurs dans $‚Ñï$.
Alors $X$ et $Y$ ont la m√™me f ¬£ssi. $X$ et $Y$ ont la m√™me loi.
\[ G_X = G_Y \iff ‚Ñô_X = ‚Ñô_Y. \]

\Para{Th√©or√®me}

Soit $X$ une variable al√©atoire sur $\Prob$ √† valeurs dans $‚Ñï$.
\begin{enumerate}
\item
  $X$ est d'esp√©rance finie ¬£ssi. $G_X$ est d√©rivable en $1$.
  Dans ce cas, $G_X'(1) = ùîº(X)$.
\item
  $X$ est de variance finie ¬£ssi. $G_X$ est deux fois d√©rivable en $1$.
  Dans ce cas, on a $G_X''(1) =ùîº\bigl[ X(X-1) \bigr]$,
  de sorte que $ùïç(X) = G_X''(1) + G_X'(1) - G_X'(1)^2$.
  Il faut savoir retrouver cette derni√®re formule.
\end{enumerate}

\Para{Remarque}

Si $X$ n'est pas √† valeurs dans $‚Ñï$, la fonction g√©n√©ratrice $G_X$ n'est pas d√©finie.
On travaille g√©n√©ralement avec la \emph{fonction caract√©ristique}
$œÜ_X(t) = ùîº\bigl(\me^{\I t X}\bigr)$, qui est toujours d√©finie sur $‚Ñù$.

% -----------------------------------------------------------------------------
\section{Couples et suites de variables al√©atoires}

\subsection{Couples de variables al√©atoires}

\Para{D√©finition}

Soit $\Prob$ un espace probabilis√©,
$\Fn{X}{Œ©}{E}$ et $\Fn{Y}{Œ©}{F}$ deux variables al√©atoires discr√®tes.
Notons $Z$ la variable al√©atoire discr√®te $Z=(X,Y)$.
La loi de $Z$ s'appelle la \emph{loi conjointe} du couple $(X,Y)$,
et les lois de $X$ et de $Y$ s'appellent les \emph{lois marginales}.
Plus explicitement, notons $E = \SEnsemble{x_i}{i‚àà‚Ñï}$ et $F = \SEnsemble{y_j}{j‚àà‚Ñï}$.
\begin{itemize}
\item
  La loi conjointe du couple $(X,Y)$ est caract√©ris√©e par
  la famille $(p_{i,j})_{(i,j)‚àà‚Ñï^2}$ o√π $‚àÄ(i,j)‚àà‚Ñï^2$,
  \[ p_{i,j} = ‚Ñô\bigl(Z = (x_i,y_j)\bigr) = ‚Ñô( X = x_i, Y = y_j ) \]
\item
  La loi marginale de $X$ est caract√©ris√©e par
  la famille $(q_i)_{i‚àà‚Ñï}$ o√π $‚àÄi‚àà‚Ñï$,
  \[ q_i = ‚Ñô(X = x_i) \]
\item
  La loi marginale de $Y$ est caract√©ris√©e par
  la famille $(r_j)_{j‚àà‚Ñï}$ o√π $‚àÄj‚àà‚Ñï$,
  \[ r_j = ‚Ñô(Y = y_j) \]
\end{itemize}

\Para{Proposition}

Connaissant la loi conjointe d'un couple de variables al√©atoires,
on peut d√©terminer les lois marginales.
En effet, avec les m√™mes notations, on a
\[ ‚àÄi‚àà‚Ñï\+ q_i = ‚àë_{j‚àà‚Ñï} p_{i,j} \quad \text{et}\quad ‚àÄj‚àà‚Ñï\+ r_j = ‚àë_{i‚àà‚Ñï} p_{i,j}. \]

Attention toutefois, il n'est pas possible de d√©terminer la loi conjointe √†
partir des lois marginales, sauf si l'on sait que $X$ et $Y$ sont ind√©pendantes (voir ci-apr√®s).

\subsection{Ind√©pendance}

\Para{D√©finition}

Soit $\Fn{X}{Œ©}{E}$ et $\Fn{Y}{Œ©}{F}$ deux variables al√©atoires sur $\Prob$.
On dit que $X$ et $Y$ sont \emph{ind√©pendantes} ¬£ssi. $‚àÄ(x,y)‚ààE√óF$,
\[ ‚Ñô(X = x, Y = y) = ‚Ñô(X = x) \, ‚Ñô(Y = y). \]

\Para{Proposition}

Soit $\Fn{X}{Œ©}{E}$ et $\Fn{Y}{Œ©}{F}$ deux variables al√©atoires ind√©pendantes sur $\Prob$.
Si $A‚äÇE$ et $B‚äÇF$, alors \[ ‚Ñô(X‚ààA, Y‚ààB) = ‚Ñô(X‚ààA) \, ‚Ñô(Y‚ààB). \]

\Para{Proposition}

Soit $\Prob$ un espace probabilis√©, $\Fn{X}{Œ©}{E}$ et $\Fn{Y}{Œ©}{F}$ deux variables al√©atoires discr√®tes. Soit $\Fn{f}{E}{E'}$ et $\Fn{g}{F}{F'}$ deux fonctions quelconques.
Si $X$ et $Y$ sont ind√©pendantes, alors les variables al√©atoires $f(X)$ et $g(Y)$ sont √©galement ind√©pendantes.

\Para{Proposition}

Soit $X‚àà\LL1$ et $Y‚àà\LL1$.
Si $X$ et $Y$ sont ind√©pendantes, alors $XY‚àà\LL1$
et $ùîº(XY) = ùîº(X) \,ùîº(Y)$.

\Para{Corollaire}

Soit $X$ et $Y$ deux variables al√©atoires discr√®tes √† valeurs dans $E$ et $F$ respectivement.
Soit $\Fn f E‚Ñù$ et $\Fn gF‚Ñù$ deux fonctions quelconques.
Si $X$ et $Y$ sont ind√©pendantes et si $f(X)$ et $g(Y)$ sont d'esp√©rances finies,
alors $f(X)\, g(Y)$ est √©galement d'esp√©rance finie et
\[ ùîº\bigPa{f(X)\,g(Y)} = ùîº\bigPa{f(X)} \, ùîº\bigPa{g(Y)}. \]

\Para{Proposition}[fonction g√©n√©ratrice de la somme de deux variables al√©atoires ind√©pendantes]

Soit $\Prob$ un espace probabilis√©,
$X$ et $Y$ deux variables al√©atoires discr√®tes √† valeurs dans $‚Ñï$.
Notons $G_X$ (respectivement $G_Y$) la fonction g√©n√©ratrice de $X$ (resp. $Y$),
qui est absolument convergente sur $\mathcal{D}_X$ (resp. $\mathcal{D}_Y$)
et de rayon de convergence $R_X$ (resp. $R_Y$).
Si $X$ et $Y$ sont ind√©pendantes, alors
\begin{itemize}
\item
  $\mathcal{D}_{X+Y} ‚äÉ\mathcal{D}_X ‚à©\mathcal{D}_Y$,
\item
  $R_{X+Y} ‚â•\min(R_X, R_Y)$,
\item
  $‚àÄt‚àà\mathcal{D}_X ‚à©\mathcal{D}_Y$, on a $G_{X+Y} (t) = G_X(t) G_Y(t)$.
\end{itemize}

\Para{Exemple}

Utiliser ce r√©sultat pour montrer que si $X_1, \dots, X_n$ sont des variables (mutuellement) ind√©pendantes qui suivent une loi de Bernoulli $\mathcal{B}(p)$, alors $S =‚àë_{k=1}^n X_k$ suit une loi binomiale $\mathcal{B}(n,p)$.

\subsection{Covariance, corr√©lation}

\Para{Proposition-D√©finitions}

Soit $X$ et $Y$ deux variables al√©atoires de $\LL2$ d'esp√©rances $Œº_X$ et $Œº_Y$.
Alors la variable al√©atoire $(X - Œº_X) (Y - Œº_Y)$ est d'esp√©rance finie.
On appelle \emph{covariance de $X$ et de $Y$} le r√©el
\[ \Cov(X,Y) = ùîº\bigl[ (X-Œº_X)(Y-Œº_Y) \bigr]. \]
On a √©galement
\[ \Cov(X,Y) = ùîº(XY) - Œº_X Œº_Y = ùîº(XY) - ùîº(X)ùîº(Y). \]

\Para{Proposition}

Soit $X$, $Y$ et $Z$ trois variables al√©atoires de $\LL2$
et $(a,b)‚àà‚Ñù^2$. On a
\begin{enumerate}
\item
  $\Cov(‚ãÖ,‚ãÖ)$ est une forme bilin√©aire sym√©trique positive
  (mais non d√©finie positive) sur $\LL2$, c.-√†-d.

  \begin{enumerate}
  \item
    $\Cov(aX+bY,Z) = a\Cov(X,Z) + b\Cov(Y,Z)$;
  \item
    $\Cov(X,aY+bZ) = a\Cov(X,Y) + b\Cov(X,Z)$;
  \item
    $\Cov(X,Y) = \Cov(Y,X)$;
  \item
    $\Cov(X,X) = ùïç(X)‚â•0$.
  \end{enumerate}
\item
  $ùïç(aX+bY) = a^2ùïç(X) + b^2ùïç(Y) + 2ab \Cov(X,Y)$.
\item
  Si $X$ et $Y$ sont ind√©pendantes, $\Cov(X,Y) = 0$.
\end{enumerate}

\Para{D√©finition}

Soit $X$ et $Y$ deux variables al√©atoires de $\LL2$ et de variances non nulles.
On appelle \emph{coefficient de corr√©lation lin√©aire de $X$ et de $Y$} le r√©el
\[ œÅ(X,Y) = \frac{\Cov(X,Y)}{‚àö{ùïç(X)ùïç(Y)}} \]

\Para{Proposition}

Dans ces conditions,
\begin{itemize}
\item
  $\Abs{œÅ(X,Y)}‚â§1$
\item
  $œÅ(X,Y) = ¬±1$ ¬£ssil. existe $(a,b)‚àà‚Ñù^2$ tels que
  $Y = aX+b$ presque s√ªrement.
\end{itemize}

\subsection{Suites de variables al√©atoires}

\Para{D√©finition}

Soit $X_1, \dots, X_n$ des variables al√©atoires sur $\Prob$, avec
$X_i$ √† valeurs dans $E_i$.
On dit que les variables $X_1, \dots, X_n$ sont \emph{mutuellement ind√©pendantes}
¬£ssi. pour tous $(x_1, \dots, x_n) ‚àà‚àè_{i=1}^n E_i$, on a
\[ ‚Ñô(X_1 = x_1, X_2 = x_2, \dots, X_n = x_n) = ‚àè_{i=1}^n ‚Ñô(X_i = x_i). \]

\Para{D√©finition}

Soit $(X_n)_{n‚àà‚Ñï}$ une suite de variables al√©atoires.
On dit que les variables al√©atoires $(X_n)_{n‚àà‚Ñï}$ sont \emph{mutuellement ind√©pendantes} ¬£ssi. pour tout $n‚àà‚Ñï$, les variables al√©atoires $X_0, \dots, X_n$ sont mutuellement ind√©pendantes.

\Para{Remarques}
\begin{itemize}
\item
  \og{}Mutuellement ind√©pendantes\fg{} entra√Æne \og{}deux √† deux ind√©pendantes\fg{}; \emph{la r√©ciproque est fausse}.
\item
  En l'absence de pr√©cision, \og{}ind√©pendantes\fg{} signifie \og{}mutuellement ind√©pendantes\fg{}.
\end{itemize}

\Para{Th√©or√®me d'existence}

Si on se donne pour chaque $n‚àà‚Ñï$ une loi de probabilit√© discr√®te $\mathcal{P}_n$ sur $‚Ñù$,
alors il existe un espace probabilis√© $\Prob$
et une suite de variables al√©atoires r√©elles discr√®tes \emph{ind√©pendantes} $(X_n)_{n‚àà‚Ñï}$ telles que $X_n$ suit la loi $\mathcal{P}_n$ pour tout $n$.

Plus pr√©cis√©ment,
soit $(x_{n,k})_{(n,k)‚àà‚Ñï^2}$ et $(p_{n,k})_{(n,k)‚àà‚Ñï^2}$ deux familles de r√©els telles que
\begin{itemize}
\item
  pour tout $n‚àà‚Ñï$ fix√©, la suite $(x_{n,k})_{k‚àà‚Ñï}$ soit injective;
\item
  pour tous $(n,k)‚àà‚Ñï^2$, $p_{n,k}‚â•0$;
\item
  pour tout $n‚àà‚Ñï$, la s√©rie $‚àë_k p_{n,k}$ converge et $‚àë_{k=0}^{+‚àû} p_{n,k} = 1$.
\end{itemize}

Pour $n‚àà‚Ñï$, on pose $E_n = \SEnsemble{x_{n,k}}{k‚àà‚Ñï}$.
Alors il existe un espace probabilis√© $\Prob$
et une suite de variables al√©atoires r√©elles discr√®tes $(X_n)_{n‚àà‚Ñï}$ sur $\Pro$ telles que:
\begin{itemize}
\item
  les variables al√©atoires $(X_n)_{n‚àà‚Ñï}$ sont ind√©pendantes;
\item
  pour tout $n‚àà‚Ñï$, la variable al√©atoire $X_n$ est √† valeurs dans $E_n$
  et sa loi est d√©finie par
  \[ ‚àÄk‚àà‚Ñï\+‚Ñô(X_n = x_{n,k}) = p_{n,k}. \]
\end{itemize}

\Para{Remarque}

En g√©n√©ral, $Œ©$ n'est pas d√©nombrable et $\T‚â†\Part(Œ©)$.

\subsection{R√©sultats asymptotiques}

\Para{Th√©or√®me}[approximation de la loi binomiale par une loi de Poisson]

Soit $(p_n)_{n‚àà‚Ñï}$ une suite num√©rique √† valeurs dans $[0,1]$.
Soit $(X_n)_{n‚àà‚Ñï}$ une suite de variables al√©atoires r√©elles
de loi binomiale $\mathcal{B}(n,p_n)$.
Si $np_n \ToninfŒª‚àà‚Ñù$, alors
\[ ‚Ñô(X_n = k) \Toninf \frac{\me^{-Œª} Œª^k}{k!}. \]

\Para{Th√©or√®me}[loi faible des grands nombres]

Soit $(X_n)_{n‚â•1}$ une suite de variables al√©atoires r√©elles
deux √† deux ind√©pendantes, de m√™me loi et admettant un moment d'ordre 2.
Notons $Œº= ùîº(X_1)$ et
$S_n = ‚àë_{k=1}^n X_k$.
Alors
\[ ‚Ñô\left( \left| \frac{S_n}{n} - Œº\right| ‚â•Œµ\right) \Toninf 0. \]

\Para{Remarques}
\begin{itemize}
\item
  La quantit√© $\frac{S_n}{n}$ s'appelle la \emph{moyenne empirique} de $(X_n)_{n‚â•1}$.
\item
  Le r√©sultat pr√©c√©dent reste vrai si l'on remplace l'hypoth√®se \og{}admettre un moment d'ordre 2\fg{}
  par l'hypoth√®se plus faible \og{}√™tre d'esp√©rance finie\fg{}.
\end{itemize}

% -----------------------------------------------------------------------------
\section{Lois usuelles}

\subsection{Lois finies}

\Para{Loi uniforme}

On dit que $X$ suit la loi uniforme sur l'ensemble fini $F$,
et on note $X‚Ü™\mathcal{U}(F)$
si $X$ est une variable al√©atoire discr√®te √† valeurs dans $F$ telle que
\[ ‚àÄx‚ààF \+ ‚Ñô(X=x) = \frac{1}{\Card(F)}. \]
Par exemple, si $F = \Dcro{1,n}$, alors:
\[ ùîº(X) = \frac{n+1}{2}, \quad ùïç(X) = \frac{n^2-1}{12}, \quad G_X(t) = \frac{t(1-t^n)}{n(1-t)}. \]

\Para{Loi de Bernoulli}

On dit que $X$ suit la loi de Bernoulli de param√®tre $p‚àà[0,1]$,
et on note $X‚Ü™\mathcal{B}(p)$
si $X$ est une variable al√©atoire discr√®te √† valeurs dans $\{0,1\}$ telle que
\[ ‚Ñô(X=0) = q, \quad ‚Ñô(X=1) = p, \quad \text{o√π } q = 1-p. \]
\[ ùîº(X) = p, \quad ùïç(X) = pq, \quad G_X(t) = q + pt. \]

\Para{Loi binomiale}

On dit que $X$ suit la loi binomiale de param√®tres $n‚àà‚Ñï$ et $p‚àà[0,1]$,
et on note $X‚Ü™\mathcal{B}(n,p)$
si $X$ est une variable al√©atoire discr√®te √† valeurs dans $\Dcro{0,n}$ telle que
\[ ‚àÄk‚àà\Dcro{0,n} \+ ‚Ñô(X=k) = \binom{n}{k} p^k q^{n-k},
\quad \text{o√π } q = 1-p. \]
\[ ùîº(X) = np, \quad ùïç(X) = npq, \quad G_X(t) = (q + pt)^n. \]

\subsection{Lois discr√®tes}

\Para{Loi g√©om√©trique}

On dit que $X$ suit la loi g√©om√©trique de param√®tre $p‚àà\intO{0,1}$,
et on note $X‚Ü™\mathcal{G}(p)$
si $X$ est une variable al√©atoire discr√®te √† valeurs dans $‚Ñï^*$ telle que
\[ ‚àÄk‚àà‚Ñï^* \+ ‚Ñô(X=k) = q^{k-1} p,
\quad \text{o√π } q = 1-p. \]
\[ ùîº(X) = \frac{1}{p}, \quad ùïç(X) = \frac{q}{p^2}, \quad G_X(t) = \frac{pt}{1-qt}. \]

\Para{Loi de Poisson}

On dit que $X$ suit la loi de Poisson de param√®tre $Œª‚àà‚Ñù^+$,
et on note $X‚Ü™\mathcal{P}(Œª)$
si $X$ est une variable al√©atoire discr√®te √† valeurs dans $‚Ñï$ telle que
\[ ‚àÄk‚àà‚Ñï\+ ‚Ñô(X=k) = \frac{\me^{-Œª} Œª^k}{k!}. \]
\[ ùîº(X) = Œª, \quad ùïç(X) = Œª, \quad G_X(t) = \me^{Œª(t-1)}. \]

% -----------------------------------------------------------------------------
\section{Exercices}

\Exercice

D√©montrer les formules de la partie \og{}lois usuelles\fg{}.

\Exercice[paradoxe de St Petersbourg]

Une banque vous propose de jouer au jeu suivant:
votre mise est de 100‚Ç¨.
Ensuite, vous lancez une pi√®ce √©quilibr√©e jusqu'√† ce que vous obteniez \og{}pile\fg{}
On note $X$ le nombre de lanc√©s n√©cessaires.
Votre gain est de $G = 2^X$.
\begin{enumerate}
\item
  \begin{enumerate}
  \item
    Montrer que $X$ est √† valeurs dans $‚Ñï^*‚à™\{+‚àû\}$.
  \item
    Calculer $‚Ñô(X = +‚àû)$.
  \item
    Reconna√Ætre la loi de $X$.
  \end{enumerate}
\item
  Calculer $ùîº(G)$. Devriez-vous jouer √† ce jeu?
\item
  En fait, si $G$ est trop √©lev√©, la banque fera faillite.
  D'apr√®s Wikipedia, le PIB mondial pour 2013 est environ $73~\mathrm{TUS\$}$ (Wikipedia).
  On note $H = \min(G,2^{50})$ le gain corrig√©.
  D√©terminer l'esp√©rance de $H$.
  Devriez-vous jouer √† ce jeu?
\end{enumerate}

\Exercice

Environ $5\%$ des r√©servations a√©riennes sur une ligne donn√©e ne sont
pas utilis√©es, et c'est pourquoi une compagnie vend 100 billets pour
97 places; on parle de \og{}surbooking\fg{}.
Quelle est la probabilit√© pour que tous les passagers aient une place?

\Exercice[loi de Pascal]

Soit $(X_n)_{n‚àà‚Ñï^*}$ une suite de variables al√©atoires ind√©pendantes
suivant une loi de Bernoulli $\mathcal{B}(p)$ avec $p‚àà\intOF{0,1}$.
Soit $k‚àà‚Ñï$ fix√©.
On note $T = \min \Ensemble{n‚àà‚Ñï}{X_1 + \dots + X_n = k}‚àà‚Ñï‚à™\acco{‚àû}$.
\begin{enumerate}
\item
  D√©crire en fran√ßais ce que repr√©sente $T$.
\item
  Montrer que $T<‚àû$ presque s√ªrement.
  On pourra introduire $S_n = X_1 + \dots + X_n$
  et utiliser la loi des grands nombres pour montrer que
  $‚Ñô\bigPa{\frac{S_n}{n} ‚â§\frac{p}{2}} \to 0$ quand $n\to+‚àû$.
\item
  D√©terminer la loi de $T$.
  On dit que $T$ suit la loi de Pascal de param√®tres $k$ et $p$.
\item
  D√©terminer l'esp√©rance, la variance de $T$
  et la fonction g√©n√©ratrice de $T$.
\item
  Soit $U = Y_1 + \dots + Y_k$ o√π $Y_i‚Ü™\mathcal{G}(p)$.
  Montrer que $T$ et $U$ ont la m√™me loi.
\end{enumerate}

\Exercice

Soit $(X_{i,j})_{1‚â§i,j‚â§n}$ une famille de variables al√©atoires ind√©pendantes de m√™me loi telles que $P(X_{i,j} = 1) = ‚Ñô(X_{i,j} = -1) = \frac12$.
On note $M$ la matrice dont les coefficients sont les $(X_{i,j})$.
Quelle est l'esp√©rance du d√©terminant de $M$?

\Exercice

On consid√®re une exp√©rience al√©atoire ayant une probabilit√© $p$ de r√©ussir et $1-p$ d'√©chouer.
On r√©p√®te l'exp√©rience de fa√ßon ind√©pendante jusqu'√† obtention de $n$ succ√®s.
On note $X$ le nombre d'essais n√©cessaires √† l'obtention de ces $n$ succ√®s.
\begin{enumerate}
\item
  Reconna√Ætre la loi de $X$ lorsque $n=1$.
\item
  D√©terminer la loi de $X$ dans le cas g√©n√©ral.
\item
  Exprimer le d√©veloppement en s√©rie enti√®re de
  $(1-t)^{-n-1}$.
\item
  D√©terminer la fonction g√©n√©ratrice de $X$
  et en d√©duire l'esp√©rance de $X$.
\end{enumerate}

\Exercice
\begin{enumerate}
\item
  Soit $X‚Ü™\mathcal{P}(Œª)$.
  Montrer que l'√©v√©nement \og{}$X$ est pair\fg{} est plus probable que l'√©v√©nement \og{}$X$ est impair\fg{}.
\item
  M√™me question avec $X‚Ü™\mathcal{G}(p)$.
\end{enumerate}

\Exercice

Soit $X‚Ü™\mathcal{P}(Œª)$ et $Y‚Ü™\mathcal{P}(Œº)$ deux variables al√©atoires ind√©pendantes.
Quelle est la loi de $X+Y$?

\Exercice

Le jour de l'examen de fin d'ann√©e, $n$ √©l√®ves n'ont pas assez soign√© la pr√©sentation de leur copie.
Le correcteur, plut√¥t que de s'escrimer √† lire d'inf√¢mes brouillons, d√©cide de noter au hasard, de mani√®re ind√©pendante, les $n$ copies, en leur attribuant une note enti√®re, au hasard, entre 0 et 20.
On note $X_n$ la variable al√©atoire √©gale √† la meilleure note du groupe.
\begin{enumerate}
\item
  Soit $k‚àà\Dcro{0,20}$.
  Calculer la probabilit√© que toutes les notes soient inf√©rieures ou √©gales √† $k$.
\item
  \begin{enumerate}
  \item
    Calculer $‚Ñô(X_n < k \mid X_n‚â§k)$.
  \item
    En d√©duire $‚Ñô( X_n = k \mid X_n‚â§k)$.
  \end{enumerate}
\item
  Calculer $‚Ñô(X_n = k)$ et d√©terminer sa limite lorsque $n \to‚àû$.
  Interpr√©ter.
\end{enumerate}

\Exercice[lois sans viellissement]

Soit $X$ une variable al√©atorie √† valeurs dans $‚Ñï^*$,
telle que $‚àÄn‚àà‚Ñï^*$, $‚Ñô(X=n) > 0$.
On suppose de plus que pour tous $(n,p)‚àà‚Ñï^2$,
\[ ‚Ñô(X > n+p \;|\; X > p) = ‚Ñô(X > n). \]
Montrer que $X$ suit une loi g√©om√©trique.

\Exercice

Expliquer pourquoi $99,\!9\,\%$ des gens poss√®dent un nombre de jambes strictement sup√©rieur √† la moyenne.

\Exercice

Soit $X‚Ü™\mathcal{G}(p)$.
On pose $Y = 1/X$. Calculer $ùîº(Y)$.

\Exercice[√† conna√Ætre]

Soit $X$ une variable al√©atoire √† valeurs dans $‚Ñï$.
\begin{enumerate}
\item
  \begin{enumerate}
  \item
    Montrer que que $‚Ñô(X = n) = ‚Ñô(X > n-1) - ‚Ñô(X > n)$ pour tout $n‚àà‚Ñï^*$.
  \item
    Si $X‚àà\LL1$, montrer que $n‚Ñô(X>n) \Toninf 0$.
  \item
    Si $X‚àà\LL1$, montrer que \[ ùîº(X) = ‚àë_{n‚â•0} ‚Ñô(X > n). \]
  \item
    Si $X‚àâ\LL1$, montrer que la s√©rie $‚àë_n ‚Ñô(X>n)$ diverge.
  \end{enumerate}
\item
  Si $X‚àà\LL2$, montrer de m√™me que
  \[ ùîº(X^2) = ‚àë_{n‚â•0} (2n+1) \, ‚Ñô(X > n). \]
\end{enumerate}

\Exercice

Soit $X‚Ü™\mathcal{P}(Œª)$.
Montrer que $‚Ñô\bigl(X‚â§\fracŒª2\bigr)‚â§\frac4Œª$
et $‚Ñô\bigl(X‚â•2Œª\bigr)‚â§\frac1Œª$.

\Exercice

Soit $X$ et $Y$ deux variables al√©atoires de lois de Bernoulli respectives $\mathcal{B}(p)$ et $\mathcal{B}(p')$.
Montrer qu'elles sont ind√©pendantes ¬£ssi. $\Cov(X,Y) = 0$.

\Exercice

Soit $X$ une variable al√©atoire discr√®te √† valeurs dans $E$
et $\Fn{f}{E}{F}$ une application.
√Ä quelle condition les variables al√©atoires $X$ et $f(X)$ sont-elles ind√©pendantes?

\Exercice

Soit $X_1, \dots, X_n$ des variables al√©atoires ind√©pendantes √† valeurs dans $‚Ñï$.
On pose $Y = Œ±_1 X_1 + \dots + Œ±_n X_n$ o√π $\nUpletŒ±1n ‚àà‚Ñï^n$.
Exprimer la s√©rie g√©n√©ratrice $G_Y$ en fonction des $G_{X_i}$.

\Exercice

On consid√®re une succession (infine) de tirages √† \og{}pile ou face\fg{}, avec une pi√®ce donnant \og{}pile\fg{} avce une probabilit√© $p‚àà\intO{0,1}$.
On note $N$ le nombre de tirages n√©cessaires pour avoir le premier \og{}pile\fg{}.
On effectue alors $N$ nouveaux tirages, et l'on note $X$ le nombre de \og{}pile\fg{} obtenus pendant ces nouveaux tirages.
Montrer que $ùîº(X) = 1$.

\Exercice[loi binomiale et loi de Poisson]

Soit $(X_n)$ une suite de variables al√©atoires telles que $X_n‚Ü™\mathscr{B}(n,p_n)$
avec $p_n = \frac{Œª}{n}$.
\begin{enumerate}
\item
  D√©terminer la limite de $ùîº(X_n)$ et de $ùïç(X_n)$.
\item
  D√©terminer la limite de $‚Ñô(X_n = k)$ quand $n\to+‚àû$.
\item
  Comment interpr√©ter ces r√©sultats?
\end{enumerate}

\Exercice

Dans une grande ville, il y a en moyenne un suicide par jour.
Combien y a-t-il, en moyenne, de jours de l'ann√©e o√π au moins $5$ personnes
se suicident?

\Exercice

Tous les soirs, au lieu de r√©viser ses cours de pr√©pa, Kevin va rusher Stratholme
dans l'espoir de looter la monture du Baron Vaillefendre.
\begin{enumerate}
\item
  √âtant donn√© que WoW est un programme informatique (consid√©r√© comme constant),
  par quelle loi mod√©liseriez-vous cette exp√©rience?
\item
  Il semblerait que la probabilit√© de dropper la monture soit de $0,7\%$.
  Au bout de combien de jours Kevin peut-il esp√©rer frimer sur le destrier de la mort?
  Au fait, d'o√π peut provenir ce chiffre de $0,7\%$?
\item
  Quelle est la probabilit√© d'arriver √† la dropper en moins de 210 jours
  (entre le d√©but et la fin des cours)?
  On pourra utiliser la calculatrice, ou l'approximation par une loi de Poisson.
\item
  Question subsidiaire: que pensez-vous des chances de r√©ussite aux concours de Kevin?
\end{enumerate}

\Exercice[moindres carr√©s]
\begin{enumerate}
\item
  Soit $X‚àà\LL2$.
  Quelle valeur de $a‚àà‚Ñù$ minimise-t-elle la quantit√©
  $ùîº\bigl[ (X-a)^2 \bigr]$?
\item
  Soit $X$ et $Y$ deux variables al√©atoires de $\LL2$.
  D√©terminer $(a,b)‚àà‚Ñù^2$ qui minimise
  $ùîº\bigl[ (Y - aX-b)^2 \bigr]$.
\end{enumerate}

\Exercice

Soit $X$ et $Y$ deux variables al√©atoires √† valeurs dans $‚Ñï$ de loi conjointe
\[ ‚àÄ(i,j)‚àà‚Ñï^2 \+ ‚Ñô(X = i, Y = j) = \frac{a}{i!j!}. \]
\begin{enumerate}
\item
  D√©terminer $a$.
\item
  Reconna√Ætre les lois marginales de $X$ et de $Y$.
\item
  $X$ et $Y$ sont-elles ind√©pendantes?
\end{enumerate}

\Exercice[in√©galit√© de Jensen]

Soit $I$ un intervalle de $‚Ñù$, $\Fn{f}{I}{‚Ñù}$ une fonction convexe et
$X$ une variable al√©atoire r√©elle √† valeurs dans $I$ d'esp√©rance finie.
L'in√©galit√© de Jensen affirme alors que, si $f(X)$ est d'esp√©rance finie, on a
\[ ùîº\bigl(f(X)\bigr)‚â•f\bigl(ùîº(X) \bigr). \]
\begin{enumerate}
\item
  On suppose $f$ d√©rivable sur $I$.

  \begin{enumerate}
  \item
    Soit $Œº‚ààI$. Montrer qu'il existe $(a,b)‚àà‚Ñù^2$ tels que
    $‚àÄx‚ààI$, $f(x)‚â•ax+b$ et $f(Œº) = aŒº+ b$.
  \item
    Montrer que $ùîº(X)‚ààI$.
  \item
    Conclure.
  \end{enumerate}
\item
  (dur) Montrer que le r√©sultat de la question 1a. reste vrai
  si l'on ne suppose plus $f$ d√©rivable. Conclure.
\end{enumerate}

\Exercice[identit√© de Wald]

Soit $N$ et $(X_n)_{n‚â•1}$ des variables al√©atoires ind√©pendantes √† valeurs dans $‚Ñï$ et d'esp√©rances finies.
On suppose que les $(X_n)_{n‚â•1}$ ont toutes la m√™me loi.
On pose \[ S = ‚àë_{k=1}^N X_k. \]
\begin{enumerate}
\item
  Montrer que $G_S(t) = G_N\bigl( G_{X_1}(t) \bigr)$ pour $\Abs{t}<1$.
  On admettra que l'on peut permuter les sommes.
\item
  √âtablir l'\emph{identit√© de Wald}:
  \[ ùîº(S) = ùîº(N) \, ùîº(X_1). \]
\end{enumerate}

\end{document}
